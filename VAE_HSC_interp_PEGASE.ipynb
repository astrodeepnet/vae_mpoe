{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RNXMsF_xGll",
    "outputId": "5617eb57-4e31-4589-b609-ff6eae938374"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m beta = \u001b[32m0.01\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "beta = 0.01\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "fVYF7Jmg_YRz",
    "outputId": "ea26e7e5-e2c5-41ae-cc77-65838a0aef70"
   },
   "outputs": [],
   "source": [
    "!ls '/content/drive/My Drive/newgrid2_lr_kroupa'\n",
    "\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "hdulist = fits.open('/content/drive/My Drive/newgrid2_lr_kroupa/SB_6_Kroupa_0.1_120_LR.fits')\n",
    "np.log10(hdulist['ETS_PARA'].data['ZSTARS'] / 0.02)\n",
    "\n",
    "print(hdulist['ETS_PARA'].data['AGE'])\n",
    "\n",
    "plt.pcolor(np.log10(hdulist[0].data))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYFufV7iIS0"
   },
   "outputs": [],
   "source": [
    "def fetch_filter_data(filters):\n",
    "    filter_dict = {}\n",
    "\n",
    "    for name, filepath in filters:\n",
    "        try:\n",
    "            with open(filepath, 'r') as file:\n",
    "                wavelength, transmission = [], []\n",
    "\n",
    "                for line in file:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 2:\n",
    "                        try:\n",
    "                            wavelength.append(float(parts[0]))\n",
    "                            transmission.append(float(parts[1]))\n",
    "                        except ValueError:\n",
    "                            continue  # Skip malformed lines\n",
    "\n",
    "                filter_dict[name] = {\n",
    "                    \"wl\": wavelength,\n",
    "                    \"tr\": transmission\n",
    "                }\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for {name}: {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file for {name}: {e}\")\n",
    "\n",
    "    return filter_dict\n",
    "\n",
    "# Example local filter file paths\n",
    "filters = [\n",
    "    ['HSCg', '/content/drive/My Drive/HSC_bands/HSC.g_filter.dat'],\n",
    "    ['HSCr', '/content/drive/My Drive/HSC_bands/HSC.r_filter.dat'],\n",
    "    ['HSCi', '/content/drive/My Drive/HSC_bands/HSC.i_filter.dat'],\n",
    "    ['HSCz', '/content/drive/My Drive/HSC_bands/HSC.z_filter.dat'],\n",
    "    ['HSCY', '/content/drive/My Drive/HSC_bands/HSC.Y_filter.dat']\n",
    "]\n",
    "\n",
    "filer_names = [name for name, _ in filters]\n",
    "\n",
    "filter_data = fetch_filter_data(filters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G7GVR-p2RxFz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "spec_points = 100\n",
    "spec_range = (3900, 10200)\n",
    "\n",
    "def bin_spectrum(spec, wl, spec_range, spec_points):\n",
    "    min_wl, max_wl = spec_range\n",
    "    bins = np.linspace(min_wl, max_wl, spec_points + 1)\n",
    "    mean_values = []\n",
    "    wl_values = []\n",
    "\n",
    "    for i in range(len(bins) - 1):\n",
    "        bin_mask = (wl >= bins[i]) & (wl < bins[i+1])\n",
    "        bin_data = spec[bin_mask]\n",
    "        mean_values.append(bin_data.mean() if bin_data.size > 0 else (bins[i] + bins[i+1]) / 2)\n",
    "        wl_values.append(0.5*(bins[i] + bins[i+1]))\n",
    "    return np.array(mean_values), np.array(wl_values)\n",
    "\n",
    "\n",
    "def get_waves(hdr):\n",
    "     waves = hdr['CRVAL1'] - (hdr['CRPIX1']-1.0)*hdr['CDELT1'] + ( np.arange(0., hdr['NAXIS1']) ) * hdr['CDELT1']\n",
    "     ran = [waves[0], waves[-1]]\n",
    "     return waves\n",
    "\n",
    "\n",
    "\n",
    "def read_fits_files(directory):\n",
    "    # Define the file pattern to match\n",
    "    file_pattern = os.path.join(directory, \"SB_?_Kroupa_0.1_120_LR.fits\")\n",
    "    fits_files = glob.glob(file_pattern)\n",
    "\n",
    "    all_spectra = []\n",
    "    all_params = []\n",
    "\n",
    "    for fits_file in fits_files:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            spectra = hdul[0].data  # Extracting spectral data\n",
    "            params = hdul[1].data  # Extracting table data\n",
    "            wl = get_waves(hdul[0].header)\n",
    "            all_spectra.extend(spectra*wl**2)\n",
    "            all_params.append(np.array([tuple(row) for row in params]))  # Ensure structured array consistency\n",
    "\n",
    "    # Stack spectra along a new axis if necessary (e.g., assuming same dimensions)\n",
    "    stacked_spectra = np.array(all_spectra)  # Convert list to numpy array\n",
    "\n",
    "    # Convert list of structured arrays into a single structured array\n",
    "    structured_params = np.concatenate(all_params) if all_params else None\n",
    "\n",
    "    # Create an Astropy Table\n",
    "    result_table = Table(rows=structured_params, names=params.names)\n",
    "\n",
    "    wl = get_waves(hdul[0].header)\n",
    "    return stacked_spectra, result_table, wl\n",
    "\n",
    "# Example usage\n",
    "#directory = \"/content/drive/My Drive/EMILES/\"  # Change to the directory containing your FITS files\n",
    "#spectra, param_table, wl = read_fits_files(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "U7z-QS8pUCOp",
    "outputId": "17ddd638-17fb-4d32-b33a-4ea0631225d2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No FITS files found matching pattern.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([interp(log_age, log_met)[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m interp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interpolators])\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Usage Example\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m lages, lmets, flx, wl = \u001b[43mread_fits_files\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/drive/My Drive/newgrid2_lr_kroupa/SB_*_Kroupa_0.1_120_LR.fits\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m spectrum_interp = SpectrumInterpolator(lages, lmets, flx)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Evaluate spectrum at specific age and metallicity\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mread_fits_files\u001b[39m\u001b[34m(pattern)\u001b[39m\n\u001b[32m      9\u001b[39m files = \u001b[38;5;28msorted\u001b[39m(glob.glob(pattern))  \u001b[38;5;66;03m# Get all relevant FITS files\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo FITS files found matching pattern.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m spectra_list = []\n\u001b[32m     14\u001b[39m ages = []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No FITS files found matching pattern."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from scipy import interpolate\n",
    "\n",
    "def read_fits_files(pattern=\"SB_*_Kroupa_0.1_120_LR.fits\"):\n",
    "    \"\"\"Reads FITS files and constructs a 3D spectral array.\"\"\"\n",
    "\n",
    "    files = sorted(glob.glob(pattern))  # Get all relevant FITS files\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No FITS files found matching pattern.\")\n",
    "\n",
    "    spectra_list = []\n",
    "    ages = []\n",
    "    mets = []\n",
    "\n",
    "    for file in files:\n",
    "        with fits.open(file) as hdul:\n",
    "            primary_data = hdul[0].data  # Spectra\n",
    "            params = hdul[\"ETS_PARA\"].data  # Age & metallicity\n",
    "            wl = hdul[3].data['BFIT']  # Wavelengths\n",
    "            primary_data = np.array([fl*wl**2 for fl in primary_data])\n",
    "            age = params[\"AGE\"]  # Extract age\n",
    "            met = params[\"ZSTARS\"]  # Extract metallicity\n",
    "            spectra_list.append(primary_data[age > 100])\n",
    "            ages.append(np.log10(age)[age > 100])\n",
    "            mets.append(np.round(np.log10(met/0.02), 2)[age > 100])\n",
    "\n",
    "    spectra_array = np.stack(spectra_list, axis=1)  # Convert list to 3D array\n",
    "\n",
    "    # Convert age and metallicity into logarithmic scales divided by 0.2\n",
    "    lages = np.array(ages)\n",
    "    lmets = np.array(mets)\n",
    "\n",
    "    return lages, lmets, spectra_array, wl\n",
    "\n",
    "class SpectrumInterpolator:\n",
    "    def __init__(self, lages, lmets, flx):\n",
    "        \"\"\"Initialize with log(age), log(metallicity), and flux array.\"\"\"\n",
    "        self.lages = np.unique(lages)  # Ensure uniqueness\n",
    "        self.mets = np.unique(lmets)\n",
    "        self.flx = flx\n",
    "        print(self.lages.shape, self.mets, flx[:, :, 0].shape)\n",
    "        # Create interpolators for each wavelength slice\n",
    "        self.interpolators = [\n",
    "            interpolate.RectBivariateSpline(self.lages, self.mets, flx[:, :, i])\n",
    "            for i in range(flx.shape[2])\n",
    "        ]\n",
    "\n",
    "    def evaluate(self, age, metallicity):\n",
    "        \"\"\"Evaluate spectrum at arbitrary log(age) and log(metallicity).\"\"\"\n",
    "        log_age = np.log10(age)\n",
    "        log_met = metallicity\n",
    "\n",
    "        return np.array([interp(log_age, log_met)[0, 0] for interp in self.interpolators])\n",
    "\n",
    "# Usage Example\n",
    "lages, lmets, flx, wl = read_fits_files('/content/drive/My Drive/newgrid2_lr_kroupa/SB_*_Kroupa_0.1_120_LR.fits')\n",
    "spectrum_interp = SpectrumInterpolator(lages, lmets, flx)\n",
    "\n",
    "# Evaluate spectrum at specific age and metallicity\n",
    "age_sample = 1100  # Example age (5 Gyr)\n",
    "met_sample = -0.50  # Example metallicity\n",
    "\n",
    "def calc_spec(wl, age = 1000, met = 0.00, z=0.0):\n",
    "    spec = spectrum_interp.evaluate(age, met)\n",
    "    return (spec, wl*(1 + z))\n",
    "\n",
    "\n",
    "'''\n",
    "def calc_spec(spectra, param_table, wl, age = 1000, met = 0.02, z=0.0):\n",
    "    da = np.abs(param_table['AGE'] - age)\n",
    "    dm = np.abs(param_table['ZSTARS']/met - 1)\n",
    "    idx = np.where((da == np.min(da)) & (dm == np.min(dm)))[0]\n",
    "    spec = spectra[idx][0]\n",
    "    return (spec, wl*(1 + z))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djKq347LXqou",
    "outputId": "d412584f-6e71-4673-b1c2-56f9aa1ba7b1"
   },
   "outputs": [],
   "source": [
    "def download_filter_curve(url):\n",
    "    \"\"\"Download and parse the filter transmission curve from a given URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = np.loadtxt(response.iter_lines())\n",
    "    return data[:, 0], data[:, 1]  # wavelengths, transmissions\n",
    "\n",
    "def calculate_flux_and_mag(spectra_list, wavelengths_list, filters):\n",
    "    \"\"\"Calculate the flux and AB magnitude for multiple spectra and filters.\"\"\"\n",
    "    all_results = []\n",
    "    all_speclr = []\n",
    "    all_wllr = []\n",
    "\n",
    "    for spectra, wavelengths in zip(spectra_list, wavelengths_list):\n",
    "        results = []\n",
    "        speclr, wllr = bin_spectrum(spectra, wavelengths, spec_range, spec_points)\n",
    "        for filter_name, filter_url in filters:\n",
    "            #filter_wavelengths, transmissions = download_filter_curve(filter_url)\n",
    "            fd = filter_data[filter_name]\n",
    "            filter_wavelengths, transmissions = fd['wl'], fd['tr']\n",
    "            # Interpolate spectra onto the filter transmission wavelengths\n",
    "            interp_flux = interp1d(wavelengths, spectra, kind='linear', fill_value=0, bounds_error=False)\n",
    "            flux_interp = interp_flux(filter_wavelengths)\n",
    "            filter_wavelengths = np.array(filter_wavelengths)\n",
    "            # Calculate total flux (assuming simple integration)\n",
    "            total_flux = np.trapz(flux_interp * transmissions, filter_wavelengths)\n",
    "            total_flux /= np.trapz(transmissions, filter_wavelengths)\n",
    "            #total_flux /= np.nanmax(total_flux)\n",
    "\n",
    "            # Calculate AB magnitude\n",
    "            if total_flux > 0:\n",
    "                ab_magnitude = -2.5 * np.log10(total_flux) - 48.6  # AB mag formula\n",
    "            else:\n",
    "                ab_magnitude = np.inf  # Undefined magnitude for zero flux\n",
    "\n",
    "            results.append([filter_name, total_flux, ab_magnitude])\n",
    "\n",
    "        all_results.append(results)\n",
    "        all_speclr.append(speclr)\n",
    "        all_wllr.append(wllr)\n",
    "\n",
    "    return all_results, [all_speclr, all_wllr]\n",
    "\n",
    "\n",
    "filters = [\n",
    "    ['HSCg', '/content/drive/My Drive/HSC_bands/HSC.g_filter.dat'],\n",
    "    ['HSCr', '/content/drive/My Drive/HSC_bands/HSC.r_filter.dat'],\n",
    "    ['HSCi', '/content/drive/My Drive/HSC_bands/HSC.i_filter.dat'],\n",
    "    ['HSCz', '/content/drive/My Drive/HSC_bands/HSC.z_filter.dat'],\n",
    "    ['HSCY', '/content/drive/My Drive/HSC_bands/HSC.Y_filter.dat']\n",
    "]\n",
    "\n",
    "spectra_list = []\n",
    "wavelengths_list = []\n",
    "\n",
    "num_samples = 2000  # Adjust as needed\n",
    "z_vals = np.random.uniform(0, 1.2, num_samples)\n",
    "age_vals = 10**np.random.uniform(np.log10(100), np.log10(15000), num_samples)\n",
    "metdex_vals = np.random.uniform(-1.50, 0.1, num_samples)\n",
    "\n",
    "n_young = int(num_samples/10)\n",
    "\n",
    "age_young_vals = np.random.uniform(500, 2000, n_young)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spectra_list = []\n",
    "wavelengths_list = []\n",
    "param_list = []\n",
    "\n",
    "for z, age, metdex in zip(z_vals, age_vals, metdex_vals):\n",
    "    gen = calc_spec(wl, age=age, met=metdex, z=z)\n",
    "    sp = gen[0]\n",
    "    if ((age > 7000) & (np.random.random() > 0.7)):\n",
    "        wei = np.random.random()\n",
    "        age_add = np.random.uniform(100, 1500)\n",
    "        gen_add = calc_spec(wl, age=age_add, met=metdex, z=z)\n",
    "        sp = sp * (1 - wei) + gen_add[0] * wei\n",
    "        age = age * (1 - wei) + age_add * wei\n",
    "    sp = sp / np.max(sp)\n",
    "    spectra_list.append(sp)\n",
    "    wavelengths_list.append(gen[1])\n",
    "    param_list.append([z, age, metdex])  # Store the corresponding parameters\n",
    "\n",
    "print(len(spectra_list))\n",
    "print(len(wavelengths_list))\n",
    "\n",
    "mags, lr = calculate_flux_and_mag(spectra_list, wavelengths_list, filters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_array = [[[entry[1] for entry in mag_entry], params, speclr] for mag_entry, params, speclr in zip(mags, param_list, lr[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9oGBAHBoLN6",
    "outputId": "fdc5f626-b82f-45cb-9b7f-32a72d5c0b6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "output_array = [[[float(val) for val in flux_list], [float(params[0]), float(params[1]), params[2]], lr] for flux_list, params, lr in output_array]\n",
    "\n",
    "print(len(output_array))\n",
    "\n",
    "N_smpl = 40  # Number of realizations per entry\n",
    "\n",
    "# Create new array with perturbations\n",
    "dataset_rnd = []\n",
    "\n",
    "for flux_list, params, lr in output_array:\n",
    "    for _ in range(N_smpl):\n",
    "        perturbed_flux = [val + 0.1 * np.random.normal(0, 1) * val for val in flux_list]  # Add perturbation\n",
    "        dataset_rnd.append([perturbed_flux, params, lr])  # Duplicate params as required\n",
    "\n",
    "\n",
    "integrals = np.array([entry[0] / np.max(entry[0]) for entry in dataset_rnd])  # 2D array of flux values\n",
    "params = np.array([entry[1] for entry in dataset_rnd])  # 2D array of corresponding parameters\n",
    "params[:, 1] /= 1e4\n",
    "spectra = np.array([entry[2] / np.max(entry[2]) for entry in dataset_rnd])  # 2D array of corresponding parameters\n",
    "#spectra = 1e5 * np.array(spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tN42B8mxZYbx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPutUUveh86L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def build_dense_encoder_sed_branch(input_shape):\n",
    "    dense_input = keras.Input(shape=input_shape)\n",
    "#    x = layers.Dense(64, activation='relu')(dense_input)\n",
    "#    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(dense_input)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    return keras.Model(dense_input, x, name='dense_encoder_branch')\n",
    "\n",
    "def build_dense_decoder_sed(latent_dim, output_dim):\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,), name=f'z_sampling')\n",
    "    x = layers.Dense(16, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "#    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(output_dim, activation='sigmoid')(x)\n",
    "    return keras.Model(latent_inputs, outputs, name='dense_decoder')\n",
    "\n",
    "def build_encoder_sp_branch(input_shape):\n",
    "    cnn_input = keras.Input(shape=input_shape)\n",
    "    #x = layers.Conv1D(32, 3, activation='relu', strides=2, padding='same')(cnn_input)\n",
    "    #x = layers.Conv1D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    #x = layers.Conv1D(128, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = layers.Flatten()(cnn_input)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    return keras.Model(cnn_input, x, name='cnn_encoder')\n",
    "\n",
    "def build_dense_decoder_sp(latent_dim, output_dim):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Dense(16, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    #x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    #x = layers.Dense(256, activation='relu')(x)\n",
    "    #x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    outputs = layers.Dense(output_dim[0])(x)\n",
    "    #outputs = layers.Reshape(output_dim)(x)\n",
    "\n",
    "    decoder = keras.Model(latent_inputs, outputs, name='dense_decoder')\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def corner_plot(r, max_params):\n",
    "    axs = tuple(range(min(max_params, r[0].shape[1])))  # Ensure indices do not exceed max dimensions\n",
    "    fig, axes = plt.subplots(len(axs), len(axs), figsize=(10, 10))\n",
    "\n",
    "    for i, ax_i in enumerate(axs):\n",
    "        for j, ax_j in enumerate(axs):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            if i == j:\n",
    "                # Diagonal: 1D histogram\n",
    "                ax.hist(r[0][:, ax_i], bins=100, color='steelblue', alpha=0.7)\n",
    "            elif i > j:\n",
    "                # Lower triangle: 2D histogram\n",
    "                ax.hist2d(r[0][:, ax_j], r[0][:, ax_i], bins=100, cmap='Blues')\n",
    "            else:\n",
    "                # Upper triangle: empty space\n",
    "                ax.set_visible(False)\n",
    "\n",
    "            # Remove ticks for clarity\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWe1mZbH3HqO"
   },
   "outputs": [],
   "source": [
    "class SpectraVAE(keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim, beta=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_branch = build_encoder_sp_branch((input_dim,1))\n",
    "\n",
    "        self.z_mean = layers.Dense(latent_dim, name='z_mean')(self.encoder_branch.output)\n",
    "        self.z_log_var = layers.Dense(latent_dim, name='z_log_var')(self.encoder_branch.output)\n",
    "\n",
    "        self.z = Sampling()([self.z_mean, self.z_log_var])\n",
    "\n",
    "        self.encoder = keras.Model(self.encoder_branch.inputs, [self.z_mean, self.z_log_var, self.z], name='cnn_encoder')\n",
    "\n",
    "        self.decoder = build_dense_decoder_sp(latent_dim,(input_dim,1))\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta = beta\n",
    "        #super().__init__(inputs=self.encoder.input, outputs=self.decoder.output, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def apply(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return (z_mean, z_log_var, z, reconstruction)\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.apply(data)[3]\n",
    "\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            (z_mean, z_log_var, z, reconstruction) = self.apply(data)\n",
    "            reconstruction_loss = ops.mean(\n",
    "                tf.keras.backend.mean(tf.keras.backend.square((data - reconstruction)/data))\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "       }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (z_mean, z_log_var, z, reconstruction) = self.apply(data)\n",
    "        reconstruction_loss = ops.mean(\n",
    "                tf.keras.backend.mean(tf.keras.backend.square((data - reconstruction)/data))\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "        kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7w-UPVT5Vhdk",
    "outputId": "e94ead29-2d13-4ecd-8dab-0ca541d40993"
   },
   "outputs": [],
   "source": [
    "ii=1000\n",
    "for ii in np.arange(ii, ii+10):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    axs[1].plot(spectra[ii], label=\"true spectrum\")\n",
    "    axs[1].set_xlabel('Wavelength, A')\n",
    "    axs[0].bar(filer_names, integrals[ii])\n",
    "    axs[0].set_ylabel('Renormalized band flux')\n",
    "    print(params[ii])\n",
    "    fig.suptitle('z = %.2f' % (params[ii, 0]))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjgNS4eR-L9o",
    "outputId": "53b92f87-46c3-46f2-db89-2d321200acde"
   },
   "outputs": [],
   "source": [
    "spvae = SpectraVAE(100, 16, beta=beta)\n",
    "spvae.compile(optimizer=keras.optimizers.Adam())\n",
    "hsp=spvae.fit(spectra, epochs=epochs, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_mOJCpQVDjrn",
    "outputId": "fc1091cd-2c1a-4686-bab7-bbf83d936a41"
   },
   "outputs": [],
   "source": [
    "ii=1126\n",
    "for ii in np.arange(ii, ii+10):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    axs[1].plot(spectra[ii], label=\"true spectrum\")\n",
    "    s = spvae(np.reshape(spectra[ii], (1,100)))\n",
    "    s = np.reshape(s[0].numpy(),(100,))\n",
    "    axs[1].plot(s, label=\"spectrum from bandpasses\")\n",
    "    axs[0].plot(range(len(spectra[ii])), spectra[ii])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3enlRrwQXVK"
   },
   "outputs": [],
   "source": [
    "class BandPassVAE(keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim, beta=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_branch = build_dense_encoder_sed_branch((input_dim,))\n",
    "\n",
    "        self.z_mean = layers.Dense(latent_dim, name='z_mean')(self.encoder_branch.output)\n",
    "        self.z_log_var = layers.Dense(latent_dim, name='z_log_var')(self.encoder_branch.output)\n",
    "\n",
    "        self.z = Sampling()([self.z_mean, self.z_log_var])\n",
    "\n",
    "        self.encoder = keras.Model(self.encoder_branch.inputs, [self.z_mean, self.z_log_var, self.z], name='dense_encoder')\n",
    "\n",
    "        self.decoder = spvae.decoder\n",
    "        self.decoder.trainable = False  # Prevent training of the decoder\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta = beta\n",
    "        #super().__init__(inputs=self.encoder.input, outputs=self.decoder.output, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def apply(self, data):\n",
    "        data_in = data\n",
    "        z_mean, z_log_var, z = self.encoder(data_in)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return (z_mean, z_log_var, z, reconstruction)\n",
    "\n",
    "    def call(self, data):\n",
    "        (data_in, data_out) = data[0]\n",
    "        return self.apply(data_in)[3]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (data_in, data_out) = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            (z_mean, z_log_var, z, reconstruction) = self.apply(data_in)\n",
    "            reconstruction_loss = ops.mean(\n",
    "                tf.keras.backend.mean(tf.keras.backend.square((data_out - reconstruction)/data_out))\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "       }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        print(data)\n",
    "        (data_in, data_out) = data[0]\n",
    "        (z_mean, z_log_var, z, reconstruction) = self.apply(data_in)\n",
    "        reconstruction_loss = ops.mean(\n",
    "                #keras.losses.mean_squared_error(data, reconstruction),\n",
    "                tf.keras.backend.mean(tf.keras.backend.square((data_out - reconstruction)/data_out))\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "        kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        data_in  = data\n",
    "        z_mean, z_log_var, z = self.encoder(data_in)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlL1PDf0_A2t",
    "outputId": "5ec7ecf5-253c-4a9a-8baa-9b4309561dd4"
   },
   "outputs": [],
   "source": [
    "bpvae = BandPassVAE(5,16, beta=beta)\n",
    "bpvae.compile(optimizer=keras.optimizers.Adam())\n",
    "h=bpvae.fit((integrals, spectra), epochs=epochs, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rXKJubfL_3Ha",
    "outputId": "2d35fef0-9420-457e-cb58-482cd7cfb1e5"
   },
   "outputs": [],
   "source": [
    "ii=10126\n",
    "for ii in np.arange(ii, ii+10):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    axs[1].plot(spectra[ii], label=\"true spectrum\")\n",
    "    s = bpvae(np.reshape(integrals[ii], (1,5)))\n",
    "    s = np.reshape(s[0].numpy(),(100,))\n",
    "    axs[1].plot(s, label=\"spectrum from bandpasses\")\n",
    "    axs[1].set_xlabel('Wavelength, A')\n",
    "    axs[0].bar(filer_names, integrals[ii])\n",
    "    axs[0].set_ylabel('Renormalized band flux')\n",
    "    fig.suptitle('z = %.2f' % (params[ii, 0]))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMM0ENUq23UC"
   },
   "outputs": [],
   "source": [
    "def build_dense_decoder_param(latent_dim, output_dim):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Dense(16, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    outputs = layers.Dense(output_dim[0])(x)\n",
    "\n",
    "    decoder = keras.Model(latent_inputs, outputs, name='dense_decoder')\n",
    "    return decoder\n",
    "\n",
    "\n",
    "class ParamVAE(keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim, beta=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_branch = build_dense_encoder_sed_branch((input_dim,))\n",
    "\n",
    "        self.z_mean = layers.Dense(latent_dim, name='z_mean')(self.encoder_branch.output)\n",
    "        self.z_log_var = layers.Dense(latent_dim, name='z_log_var')(self.encoder_branch.output)\n",
    "\n",
    "        self.z = Sampling()([self.z_mean, self.z_log_var])\n",
    "        self.wei = np.array([10, 1, 1])\n",
    "        self.wei = self.wei / np.sum(self.wei)\n",
    "        self.encoder = bpvae.encoder\n",
    "        self.encoder.trainable = False  # Prevent training of the decoder\n",
    "\n",
    "        self.decoder = build_dense_decoder_param(latent_dim,(3,1))\n",
    "        self.decoder.trainable = True  # Prevent training of the decoder\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta = beta\n",
    "        #super().__init__(inputs=self.encoder.input, outputs=self.decoder.output, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def apply(self, data):\n",
    "        data_in = data\n",
    "        z_mean, z_log_var, z = self.encoder(data_in)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return (z_mean, z_log_var, z, reconstruction)\n",
    "\n",
    "    def call(self, data):\n",
    "        (data_in, data_out) = data[0]\n",
    "        return self.apply(data_in)[3]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (data_in, data_out) = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            (z_mean, z_log_var, z, reconstruction) = self.apply(data_in)\n",
    "            reconstruction_loss = ops.mean(\n",
    "                tf.keras.backend.square(data_out*self.wei - reconstruction*self.wei)\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "       }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        print(data)\n",
    "        (data_in, data_out) = data[0]\n",
    "        (z_mean, z_log_var, z, reconstruction) = self.apply(data_in)\n",
    "        reconstruction_loss = ops.mean(\n",
    "                #keras.losses.mean_squared_error(data, reconstruction),\n",
    "                tf.keras.backend.mean(tf.keras.backend.square(data_out - reconstruction))\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "        kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss*self.beta\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        data_in  = data\n",
    "        z_mean, z_log_var, z = self.encoder(data_in)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KanksJhfI8nJ",
    "outputId": "d0e27d05-b44d-4713-86af-2c6e9c381763"
   },
   "outputs": [],
   "source": [
    "print(params[0])\n",
    "\n",
    "parvae = ParamVAE(3,16, beta=beta)\n",
    "parvae.compile(optimizer=keras.optimizers.Adam())\n",
    "h=parvae.fit((integrals, params), epochs=epochs, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "QWR688TAKKbz",
    "outputId": "1ec82f89-de39-4a87-d6ad-d008cdce271a"
   },
   "outputs": [],
   "source": [
    "pnames = ['z', 't', '[Z/H]']\n",
    "\n",
    "s = parvae(np.reshape(integrals[:80000], (80000,5)))\n",
    "p = params[:80000]\n",
    "\n",
    "res = s - p\n",
    "\n",
    "print(s[0], p[0])\n",
    "axs = (0, 0)\n",
    "\n",
    "\n",
    "plx = p[:, axs[0]]\n",
    "ply = res[:, axs[1]]\n",
    "plt.plot(plx, ply, 'k.')\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Y52R1cOXQyBh",
    "outputId": "8351bac1-1b09-4fdc-b43f-a42a052a5e3b"
   },
   "outputs": [],
   "source": [
    "plx = p[:, axs[0]]\n",
    "ply = res[:, axs[1]]\n",
    "plt.hist2d(plx, ply, bins=100)\n",
    "#plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "BbJfbEUoX5iE",
    "outputId": "dedb963f-3e9a-4868-e98f-dd0dec145e24"
   },
   "outputs": [],
   "source": [
    "axs = (1, 1)\n",
    "\n",
    "\n",
    "plx = p[:, axs[0]]\n",
    "ply = res[:, axs[1]]\n",
    "plt.plot(plx, ply, 'k.')\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n",
    "\n",
    "plx = p[:, axs[0]] * 10\n",
    "ply = res[:, axs[1]] * 10.0\n",
    "plt.hist2d(plx, ply, bins=16)\n",
    "#plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "oh2d9cFcbikx",
    "outputId": "a51357b7-8534-487c-91ec-09b0d8771d04"
   },
   "outputs": [],
   "source": [
    "mags = np.array([24.369846, 22.666399, 21.405907, 20.927715, 20.358585])\n",
    "\n",
    "bandfl = 10**(-0.4*mags)\n",
    "\n",
    "bandfl /= np.max(bandfl)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12, 5)\n",
    "#axs[1].plot(wllr, spectra[ii], label=\"true spectrum\")\n",
    "s = bpvae(np.reshape(bandfl, (1,5)))\n",
    "s = np.reshape(s[0].numpy(),(100,))\n",
    "axs[1].plot(s, label=\"spectrum from bandpasses\")\n",
    "axs[1].set_xlabel('Wavelength, A')\n",
    "axs[0].bar(filer_names, bandfl)\n",
    "axs[0].set_ylabel('Renormalized band flux')\n",
    "#fig.suptitle('z = %.2f' % (params[ii, 0]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "s = parvae(np.reshape(bandfl, (1,5)))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxmDtvfDuVz2"
   },
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "t_hsc_ = Table.read('http://gal-03.voxastro.org/~kirg/tmp/DESI_DR1_HSCSSP_clean_RCSED.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "id": "ZO1lNOIPullK",
    "outputId": "c092ffe1-e9f6-46e3-c85e-97ecf6def10f"
   },
   "outputs": [],
   "source": [
    "hsc_int = []\n",
    "hsz_z = []\n",
    "t_hsc = t_hsc_[((t_hsc_['z'] > 0.1) & (t_hsc_['z'] < 0.95) & (t_hsc_['zwarn'] == 0))]\n",
    "\n",
    "for r in t_hsc:\n",
    "    mags = mags = np.array([r['g_kronflux_mag'], r['r_kronflux_mag'], r['i_kronflux_mag'], r['z_kronflux_mag'], r['y_kronflux_mag']])\n",
    "    bandfl = 10**(-0.4*mags)\n",
    "    bandfl /= np.max(bandfl)\n",
    "    hsc_int.append(bandfl)\n",
    "    hsz_z.append(r['z'])\n",
    "\n",
    "n = len(hsc_int)\n",
    "pnames = ['z', 't', '[Z/H]']\n",
    "\n",
    "s = parvae(np.reshape(hsc_int[:n], (n,5)))\n",
    "p = hsz_z[:n]\n",
    "\n",
    "res = s[:, 0] - p\n",
    "\n",
    "print(s[0], p[0])\n",
    "axs = (0, 0)\n",
    "\n",
    "\n",
    "plx = p[:]\n",
    "ply = res[:]\n",
    "plt.hist2d(plx, ply, bins=40)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plx = p[:]\n",
    "ply = res[:]\n",
    "plt.hist2d(p[:], s[:, 0], bins=40)\n",
    "plt.plot([0, 1], [0, 1], color='red')\n",
    "plt.ylim(np.min(p[:]), np.max(p[:]))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$ ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n",
    "\n",
    "t_hsc['z_photo'] = s[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "lwrHiqS3Cen3",
    "outputId": "98e0e197-0013-414b-a185-29418e0a47ba"
   },
   "outputs": [],
   "source": [
    "hsc_int = []\n",
    "hsz_z = []\n",
    "t_hsc = t_hsc_[((t_hsc_['z'] > 0.1) & (t_hsc_['z'] < 0.95) & (t_hsc_['zwarn'] == 0))]\n",
    "\n",
    "for r in t_hsc:\n",
    "    mags = mags = np.array([r['g_kronflux_mag'], r['r_kronflux_mag'], r['i_kronflux_mag'], r['z_kronflux_mag'], r['y_kronflux_mag']])\n",
    "    bandfl = 10**(-0.4*mags)\n",
    "    bandfl /= np.max(bandfl)\n",
    "    hsc_int.append(bandfl)\n",
    "    hsz_z.append(r['z'])\n",
    "\n",
    "n = len(hsc_int)\n",
    "pnames = ['z', 't', '[Z/H]']\n",
    "\n",
    "s = parvae(np.reshape(hsc_int[:n], (n,5)))\n",
    "p = hsz_z[:n]\n",
    "\n",
    "res = s[:, 0] - p\n",
    "print(s[0], p[0])\n",
    "axs = (0, 0)\n",
    "\n",
    "\n",
    "plx = p[:]\n",
    "ply = res[:]\n",
    "plt.plot(plx, ply, marker='.', color='black', linestyle='None', alpha=0.005)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n",
    "t_hsc['z_photo'] = s[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "sj75YrvkncHN",
    "outputId": "4d6ed38c-7a13-4ec1-ecb0-d857963b5361"
   },
   "outputs": [],
   "source": [
    "plx = p[:]\n",
    "ply = res[:]\n",
    "plt.plot(plx, ply, marker='.', color='black', linestyle=None, alpha=0.05)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "BvyhFLTWw8w-",
    "outputId": "f1fa82bb-ffdd-4e80-b2a0-dbfbb61b108a"
   },
   "outputs": [],
   "source": [
    "plx = np.array(p[:])\n",
    "ply = np.array(res[:])\n",
    "print(plx)\n",
    "# Set number of bins\n",
    "N = 20  # You can change this to whatever number of bins you want\n",
    "\n",
    "# Digitize plx into N bins\n",
    "bins = np.linspace(np.min(plx), np.max(plx), N + 1)\n",
    "indices = np.digitize(plx, bins)\n",
    "\n",
    "# Subtract median ply in each bin\n",
    "corrected_ply = ply\n",
    "for i in range(1, N + 1):\n",
    "    bin_mask = indices == i\n",
    "    if np.any(bin_mask):\n",
    "        median_val = np.median(ply[bin_mask])\n",
    "        corrected_ply[bin_mask] -= median_val\n",
    "\n",
    "# Plot the corrected data\n",
    "plt.plot(plx, corrected_ply, marker='.', color='black', linestyle='None', alpha=0.005)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$ (median subtracted)')\n",
    "plt.show()\n",
    "\n",
    "plt.hist2d(plx, ply, bins=40)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jndT5mEUzWO6",
    "outputId": "cdaae9c7-c5c7-477a-bcbd-a4be487aeefc"
   },
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clip\n",
    "\n",
    "\n",
    "N = 20\n",
    "\n",
    "# Digitize plx into N bins\n",
    "bins = np.linspace(np.min(plx), np.max(plx), N + 1)\n",
    "indices = np.digitize(plx, bins)\n",
    "\n",
    "# Subtract sigma-clipped mean of ply in each bin\n",
    "corrected_ply = ply.copy()\n",
    "for i in range(1, N + 1):\n",
    "    bin_mask = indices == i\n",
    "    if np.any(bin_mask):\n",
    "        clipped = sigma_clip(ply[bin_mask], sigma=2.5, maxiters=20)\n",
    "        mean_val = np.median(clipped.data[~clipped.mask])\n",
    "        print(np.mean(plx[bin_mask]), mean_val)\n",
    "        corrected_ply[bin_mask] -= mean_val\n",
    "\n",
    "# Plot the corrected data\n",
    "plt.plot(plx, corrected_ply, marker='.', color='black', linestyle='None', alpha=0.005)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.show()\n",
    "\n",
    "# 2D histogram\n",
    "plt.hist2d(plx, corrected_ply, bins=40)\n",
    "plt.ylim(-np.max(plx), np.max(plx))\n",
    "plt.xlabel('$' + pnames[axs[0]] + '$')\n",
    "plt.ylabel('$\\Delta ' + pnames[axs[1]] + '$')\n",
    "plt.colorbar(label='Counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "yQ2dj-G4JRXP",
    "outputId": "a1311182-f41f-4c4d-a7a2-37d01df8c336"
   },
   "outputs": [],
   "source": [
    "t_hsc[((t_hsc['z'] < 0.5) & (t_hsc['z'] > 0.25) & (t_hsc['z_photo'] <0.15) & (t_hsc['objid'] > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cxg0tI0tuvz8"
   },
   "outputs": [],
   "source": [
    "def corner_plot(r, max_params):\n",
    "    axs = tuple(range(min(max_params, r[0].shape[1])))  # Ensure indices do not exceed max dimensions\n",
    "    fig, axes = plt.subplots(len(axs), len(axs), figsize=(10, 10))\n",
    "\n",
    "    for i, ax_i in enumerate(axs):\n",
    "        for j, ax_j in enumerate(axs):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            if i == j:\n",
    "                # Diagonal: 1D histogram\n",
    "                ax.hist(r[0][:, ax_i], bins=100, color='steelblue', alpha=0.7)\n",
    "            elif i > j:\n",
    "                # Lower triangle: 2D histogram\n",
    "                ax.hist2d(r[0][:, ax_j], r[0][:, ax_i], bins=100, cmap='Blues')\n",
    "            else:\n",
    "                # Upper triangle: empty space\n",
    "                ax.set_visible(False)\n",
    "\n",
    "            # Remove ticks for clarity\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qM0LOHQsToJ0",
    "outputId": "ca340276-8498-4908-a62d-2c48b3719e9c"
   },
   "outputs": [],
   "source": [
    "r = t_hsc[t_hsc['targetid'] == 39627761148494904][0]\n",
    "\n",
    "ii = 50500\n",
    "\n",
    "print(r)\n",
    "\n",
    "mags = np.array([r['g_kronflux_mag'], r['r_kronflux_mag'], r['i_kronflux_mag'], r['z_kronflux_mag'], r['y_kronflux_mag']])\n",
    "bandfl = 10**(-0.4*mags)\n",
    "\n",
    "bandfl /= np.max(bandfl)\n",
    "\n",
    "print(params[ii])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12, 5)\n",
    "#axs[1].plot(wllr, spectra[ii], label=\"true spectrum\")\n",
    "#s = bpvae(np.reshape(bandfl, (1,5)))\n",
    "#s = np.reshape(s[0].numpy(),(100,))\n",
    "#axs[1].plot(wllr, s, label=\"spectrum from bandpasses\")\n",
    "#axs[1].set_xlabel('Wavelength, A')\n",
    "axs[0].bar(filer_names, bandfl, fill=False, edgecolor='blue')\n",
    "axs[0].bar(filer_names, integrals[ii], fill=False, edgecolor='green')\n",
    "axs[0].set_ylabel('Renormalized band flux')\n",
    "#fig.suptitle('z = %.2f' % (params[ii, 0]))\n",
    "\n",
    "s = bpvae(np.reshape(bandfl, (1,5)))\n",
    "s = np.reshape(s[0].numpy(),(100,))\n",
    "axs[1].plot(s)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "p_ls = parvae.apply(np.reshape(bandfl, (1,5)))\n",
    "\n",
    "\n",
    "p = parvae(np.reshape(bandfl, (1,5)))\n",
    "\n",
    "print(p_ls)\n",
    "\n",
    "param_evals = []\n",
    "\n",
    "nsmpl = 1000\n",
    "for i in range(nsmpl):\n",
    "    p_ls = parvae(np.reshape(bandfl, (1,5)))\n",
    "    param_evals.append(p_ls[0].numpy())\n",
    "\n",
    "param_evals = np.array(param_evals)\n",
    "plt.hist(param_evals[:, 0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(param_evals[:, 0], param_evals[:, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(param_evals[:, 0], param_evals[:, 1], 'k+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cW7aUtm-JgfK",
    "outputId": "9561b30f-290b-491b-88f9-5c7c9958aa43"
   },
   "outputs": [],
   "source": [
    "r = t_hsc[t_hsc['targetid'] == 39627761148494904][0]\n",
    "\n",
    "ii = 50500\n",
    "\n",
    "print(r)\n",
    "\n",
    "mags = np.array([r['g_kronflux_mag'], r['r_kronflux_mag'], r['i_kronflux_mag'], r['z_kronflux_mag'], r['y_kronflux_mag']])\n",
    "bandfl = 10**(-0.4*mags)\n",
    "\n",
    "bandfl /= np.max(bandfl)\n",
    "\n",
    "print(params[ii])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12, 5)\n",
    "#axs[1].plot(wllr, spectra[ii], label=\"true spectrum\")\n",
    "#s = bpvae(np.reshape(bandfl, (1,5)))\n",
    "#s = np.reshape(s[0].numpy(),(100,))\n",
    "#axs[1].plot(wllr, s, label=\"spectrum from bandpasses\")\n",
    "#axs[1].set_xlabel('Wavelength, A')\n",
    "axs[0].bar(filer_names, bandfl, fill=False, edgecolor='blue')\n",
    "axs[0].bar(filer_names, integrals[ii], fill=False, edgecolor='green')\n",
    "axs[0].set_ylabel('Renormalized band flux')\n",
    "#fig.suptitle('z = %.2f' % (params[ii, 0]))\n",
    "\n",
    "s = bpvae(np.reshape(bandfl, (1,5)))\n",
    "s = np.reshape(s[0].numpy(),(100,))\n",
    "axs[1].plot(s)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "p_ls = parvae.apply(np.reshape(bandfl, (1,5)))\n",
    "\n",
    "\n",
    "p = parvae(np.reshape(bandfl, (1,5)))\n",
    "\n",
    "print(p_ls)\n",
    "\n",
    "param_evals = []\n",
    "\n",
    "nsmpl = 1000\n",
    "for i in range(nsmpl):\n",
    "    p_ls = parvae(np.reshape(bandfl, (1,5)))\n",
    "    param_evals.append(p_ls[0].numpy())\n",
    "\n",
    "param_evals = np.array(param_evals)\n",
    "plt.hist(param_evals[:, 0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(param_evals[:, 0], param_evals[:, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(param_evals[:, 0], param_evals[:, 1], 'k+')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "rall = np.sum((integrals - bandfl)**2, axis=-1)\n",
    "\n",
    "idx = np.where(rall < 5*0.01**2)[0]\n",
    "\n",
    "p_v = params[idx]\n",
    "\n",
    "plt.plot(p_v[:, 0], p_v[:, 1], 'k+')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ue0oZVNCvYTZ"
   },
   "outputs": [],
   "source": [
    "#r = bpvae.apply(np.reshape(integrals[:80000],(80000,5,1)))\n",
    "#corner_plot(r, max_params=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "dseV82QqMX9a",
    "outputId": "7cafacdd-ec47-4b42-f76f-56003368ec2d"
   },
   "outputs": [],
   "source": [
    "t_hsc[((t_hsc['z'] < 0.99) & (t_hsc['z'] > 0.8) & (t_hsc['z_photo'] < 0.4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8gJjWbwM4DW",
    "outputId": "9b5132c4-ae3d-4443-d603-0e3b64f155af"
   },
   "outputs": [],
   "source": [
    "photoz_good = t_hsc[np.abs(t_hsc['z'] - t_hsc['z_photo']) < 0.15*(1 + t_hsc['z'])]\n",
    "print(len(photoz_good), len(t_hsc), len(photoz_good)/len(t_hsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "1r303-IXmOs6",
    "outputId": "4639a2c5-824b-4f72-c43b-ec42636e0da4"
   },
   "outputs": [],
   "source": [
    "plt.plot(params[:, 0], params[:, 2], 'k+')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM537VSZfeaEp1QLmc85QQu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
